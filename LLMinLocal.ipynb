{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68703be-09af-4a66-b573-b6e00dade1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from llm_client import VicunaLLM\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import Tool, AgentType, initialize_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e737f71e-f3e0-4162-babc-40ae2acf9f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_client import VicunaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43ee0e3d-85f7-4b79-9c90-59f6e5701893",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = VicunaLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f8dd4-dc54-418d-ae64-d801e3676c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create chunk for QnA of the document\n",
    "print(\"Creating Chunks...\")\n",
    "with open(\"airplanehistory.txt\") as f:\n",
    "    book = f.read()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.split_text(book)\n",
    "texts[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8371c672-7610-4a0e-94fe-c1edd76ce518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rizwan/anaconda3/envs/llmgen/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\", \n",
    "                                                      model_kwargs={\"device\": \"cuda\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc70fd8b-6072-4688-8f85-217617f948da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "## Here is the nmew embeddings being used\n",
    "embedding = instructor_embeddings\n",
    "\n",
    "\n",
    "vectordb = Chroma.from_texts(\n",
    "    texts, embedding, metadatas=[{\"source\": str(i)} for i in range(len(texts))],\n",
    "                                 persist_directory=persist_directory)\n",
    "# persiste the db to disk\n",
    "vectordb.persist()\n",
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "# vectordb = Chroma(persist_directory=persist_directory, \n",
    "#                   embedding_function=embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b0e9398-58a7-4086-85c6-84439e23d30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='The first flights with the power machine were made on December 17, 1903.\\nOnly five persons besides ourselves were present. These were Messrs.\\nJohn T. Daniels, W. S. Dough, and A. D. Etheridge, of the Kill Devil\\nLife-Saving Station; Mr. W. C. Brinkley, of Manteo; and Mr. John Ward,\\nof Naghead. Although a general invitation had been extended to the\\npeople living within five or six miles, not many were willing to face\\nthe rigors of a cold December wind in order to see, as they no doubt\\nthought, another flying machine not fly. The first flight lasted only 12\\nseconds, a flight very modest compared with that of birds, but it was,\\nnevertheless, the first in the history of the world in which a machine\\ncarrying a man had raised itself by its own power into the air in free\\nflight, had sailed forward on a level course without reduction of speed,\\nand had finally landed without being wrecked. The second and third\\nflights were a little longer, and the fourth lasted 59 seconds, covering\\na distance of 852 feet over the ground against a 20-mile wind.', metadata={'source': '24'})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "docs = retriever.get_relevant_documents(\"When was the first flight made and who all were present?\")\n",
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88f5f0f2-d63e-4955-a7a5-9d683b2842e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)\n",
    "\n",
    "import textwrap\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b27ccf5e-c244-485b-b98b-3e0597f8800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The first flight was made on December 17, 1903. The fourth flight was the longest, lasting 59 seconds.\n",
      "\n",
      "\n",
      "Sources:\n",
      "24\n",
      "24\n",
      "56\n",
      "56\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Query the question \n",
    "query = \"When was the first flight made and which attempt was the longest flight duration?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee84ec-9bac-4d6c-a63b-42af8f70c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c315ec86-57c1-4bc3-94d3-8d224f9d3f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87ae0949-b10a-4d01-a9f1-e04796cc2cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "from typing import List, Union, Any, Optional, Type\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re\n",
    "from langchain import PromptTemplate\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "from llm_client import VicunaLLM\n",
    "\n",
    "template = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "Google Search: A wrapper around Google Search. Useful for when you need to answer questions about current events. The input is the question to search relavant information.\n",
    "Before providing a definitive answer,no need to double-checkcredibility of these sources.\n",
    "\n",
    "Strictly use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [Google Search]\n",
    "Action Input: the input to the action, should be a question.\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "For examples:\n",
    "Question: How old is CEO of Microsoft wife?\n",
    "Thought: First, I need to find who is the CEO of Microsoft.\n",
    "Action: Google Search\n",
    "Action Input: Who is the CEO of Microsoft?\n",
    "Observation: Satya Nadella is the CEO of Microsoft.\n",
    "Thought: Now, I should find out Satya Nadella's wife.\n",
    "Action: Google Search\n",
    "Action Input: Who is Satya Nadella's wife?\n",
    "Observation: Satya Nadella's wife's name is Anupama Nadella.\n",
    "Thought: Then, I need to check Anupama Nadella's age.\n",
    "Action: Google Search\n",
    "Action Input: How old is Anupama Nadella?\n",
    "Observation: Anupama Nadella's age is 50.\n",
    "Thought: I now know the final answer.\n",
    "Final Answer: Anupama Nadella is 50 years old.\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "temp_Ins = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Question: {thought}\n",
    "Query: {query}\n",
    "Observation: {observation}\n",
    "\n",
    "### Input:\n",
    "Make a short summary of useful information from the result observation that is related to the question.\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "prompt_Ins = PromptTemplate(\n",
    "    input_variables=[\"thought\", \"query\", \"observation\"],\n",
    "    template=temp_Ins,\n",
    ")\n",
    "\n",
    "\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    \"\"\"Schema to represent a prompt for an LLM.\n",
    "\n",
    "    Example:\n",
    "        .. code-block:: python\n",
    "\n",
    "            from langchain import PromptTemplate\n",
    "            prompt = PromptTemplate(input_variables=[\"foo\"], template=\"Say {foo}\")\n",
    "    \"\"\"\n",
    "\n",
    "    input_variables: List[str]\n",
    "    \"\"\"A list of the names of the variables the prompt template expects.\"\"\"\n",
    "\n",
    "    template: str\n",
    "    \"\"\"The prompt template.\"\"\"\n",
    "\n",
    "    template_format: str = \"f-string\"\n",
    "    \"\"\"The format of the prompt template. Options are: 'f-string', 'jinja2'.\"\"\"\n",
    "\n",
    "    validate_template: bool = False\n",
    "    \"\"\"Whether or not to try validating the template.\"\"\"\n",
    "    \n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        if len(intermediate_steps) > 0:\n",
    "            regex = r\"Thought\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\\nObservation\"\n",
    "            text_match = intermediate_steps[-1][0].log\n",
    "            print(\"intermediate step:\")\n",
    "            #print(text_match)\n",
    "            if len(intermediate_steps) > 1:\n",
    "                text_match = 'Thought: ' + text_match + '\\nObservation'\n",
    "                print(\"intermediate step more than 1:\")\n",
    "                print(text_match)\n",
    "            match = re.search(regex, text_match, re.DOTALL)  \n",
    "            #print(\"matches with regex\")\n",
    "            #print(match)\n",
    "            my_list = list(intermediate_steps[-1])\n",
    "            p_INS_temp = prompt_Ins.format(thought=match.group(1).strip(), query=match.group(3).strip(), observation=my_list[1])\n",
    "            my_list[1] = llm(p_INS_temp)\n",
    "            my_tuple = tuple(my_list)            \n",
    "            intermediate_steps[-1] = my_tuple\n",
    "            \n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\" {observation}\\nThought:\"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        return self.template.format(**kwargs)\n",
    "    \n",
    "prompt = CustomPromptTemplate(input_variables=[\"input\", \"intermediate_steps\"],\n",
    "                              template=template,validate_template=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eca57c9d-0a9c-4f8a-bfd5-c5b29a5aed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        #print(match)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a44fac12-c6f4-4fa8-9e04-d67d229f2224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SERPER_API_KEY\"] = ''\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tool_google = Tool(\n",
    "        name=\"Google Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\"\n",
    "    )\n",
    "tool_names = [tool_google]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61cc0597-959b-493d-989b-a21237cdc0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\", \"\\nObservations:\"], \n",
    "    allowed_tools=tool_names\n",
    ")\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tool_names, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c9f0b20-61a1-4631-8aca-7ef31b301718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: First, I need to understand what DXOmark means and how it rates cameras.\n",
      "Action: Google Search\n",
      "Action Input: What is DXOmark and how does it rate cameras?\n",
      "Observation:\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mFor our DxOMark camera sensor reviews, we measure the image quality performance only of camera sensors that are capable of capturing images in RAW format, ... Missing: Observation. The restructured scoring system (see above: zoom and wide are now combined in the Zoom sub-score, which is on par now with Photo and Video) means that devices ... DXOMARK's Camera (previously called DxOMark Mobile) scores and rankings are based on testing every camera using an identical, extensive process ... Missing: Observation. First, apertures can be larger, which means more information can be captured in a given exposure, which in turn means less noise in captured images. Second, the ... The new DXOMARK Camera ranking. Just like Exposure, Texture, Zoom, and Bokeh, the Wide and Night scores are sub-scores of the Photo score, which in turn ... Video 28.5%. We evaluate the performance of the smartphone while recording videos in a large number of use cases, various lighting conditions and environments ... Missing: Observation. Testing is based on the smartphone camera's JPG output and also covers video mode. In addition to testing in the lab and objective evaluation, the DXOMARK ... Missing: Observation. The DxOMark Sensor score does not directly reward sensors that have above-average resolutions. Instead, the score is a measure for achievable ... dxomark measures the image qualty of cameras as Dynamic range stops or Color depth or iso performance . But how it measures the image quality ... DxO measures something, and does it consistently. But that something isn't image quality as you'd perceive it looking at well processed images.\u001b[0m\n",
      "intermediate step:\n",
      "\u001b[32;1m\u001b[1;3m Next, I will look up which phones are rated highly by DXOmark.\n",
      "Action: Google Search\n",
      "Action Input: Top rated Android phones for camera according to DXOmark\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mAll camera tests · Google Pixel 7a Camera test · OnePlus 11 Camera test · Huawei P60 Pro Camera test · Motorola Edge 40 Pro Camera test · Honor 70 Lite Camera test. The Huawei P40 Pro isn't only the best phone we have tested for photo capture, it also tops our ranking for Video with 105 points. Top Smartphones ; 1. Huawei P60 Pro. $1058 ; 2. Oppo Find X6 Pro. $908 ; 3. Honor Magic5 Pro. $1199 ; 4. Oppo Find X6. $681 ; 5. Huawei Mate 50 Pro. $1299. The Mate 40 Pro is not only the best choice for still images, but with a score of 116, it also leads our Video ranking, making it a true imaging all-rounder. All smartphone tests · Google Pixel 7a Camera test · Google Pixel 7a Display test · OnePlus 11 Camera test · OnePlus 11 Display test · TCL 40R 5G Battery test · TCL ... Released in July 2021, the Huawei P50 Pro is the current number one in the DXOMARK Camera ranking. It uses Huawei's own Kirin 9000 chipset and packs four camera ... For those who are after excellent camera, audio, and display performance without spending Ultra Premium money Google's Pixel 6 device is an excellent pick. Its ... Missing: Android | Must include:Android. Dxomark gives you the expert reviews on latest smartphones, cameras and speakers! We test and score smartphones for you to make a smart buying decision. The best smartphone front cameras · Best for Selfie Photo: Huawei P40 Pro · Best for Selfie Video: Huawei P40 Pro. DXOMARK picked four popular devices to find out which type of photography they were best suited for -- portrait, landscape, low light, zoom, and video.\u001b[0m\n",
      "intermediate step:\n",
      "intermediate step more than 1:\n",
      "Thought:  Next, I will look up which phones are rated highly by DXOmark.\n",
      "Action: Google Search\n",
      "Action Input: Top rated Android phones for camera according to DXOmark\n",
      "Observation\n",
      "\u001b[32;1m\u001b[1;3m Since the question asked for the phone with the top DXOmark score, I will focus on the top-rated phone.\n",
      "Action: Google Search\n",
      "Action Input: Which phone has the highest rating from DXOmark?\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mTop Smartphones ; 1. Huawei P60 Pro. $1058 ; 2. Oppo Find X6 Pro. $908 ; 3. Honor Magic5 Pro. $1199 ; 4. Oppo Find X6. $681 ; 5. Huawei Mate 50 Pro. $1299. We put the OnePlus 11 through our rigorous DXOMARK Camera test suite to measure its performance in photo, video, and zoom quality from an end-user perspective. With a Photo score of 140, the Huawei P40 Pro is currently the top device for still image capture in our database. The score is based on top-level photo ... All smartphone tests · Google Pixel 7a Camera test · Google Pixel 7a Display test · OnePlus 11 Camera test · OnePlus 11 Display test · TCL 40R 5G Battery test · TCL ... Dxomark gives you the expert reviews on latest smartphones, cameras and speakers! We test and score smartphones for you to make a smart buying decision. The Galaxy S22 Ultra (Exynos) earns its place on this list mainly for its display performance, where it earned a top score not only for readability but also for ... Smartphone reviews · Google Pixel 7a · Motorola Edge 40 Pro · Honor 70 Lite · Huawei P60 Pro · Xiaomi Redmi Note 12 5G · Xiaomi Redmi Note 12 Pro+ 5G · Xiaomi Redmi ... Best overall · Huawei P50 Pro (DXOMARK overall score 144) · Xiaomi Mi 11 Ultra (DXOMARK overall score 143) · Oppo Find X3 Pro (DXOMARK overall score 131) · Apple ... Best for Tele: Xiaomi Mi 10 Ultra. With a tele score of 133, the Xiaomi Mi 10 Ultra is also our number one pick for tele-zoom enthusiasts. Dual tele ... We put the Google Pixel 7a through our rigorous DXOMARK Display test suite to measure its performance across six criteria. In this test results summary, ...\u001b[0m\n",
      "intermediate step:\n",
      "intermediate step more than 1:\n",
      "Thought:  Since the question asked for the phone with the top DXOmark score, I will focus on the top-rated phone.\n",
      "Action: Google Search\n",
      "Action Input: Which phone has the highest rating from DXOmark?\n",
      "Observation\n",
      "\u001b[32;1m\u001b[1;3m Finally, I will provide the answer to the original question.\n",
      "Final Answer: According to DXOmark ratings, the Huawei P60 Pro is the phone with the top DXOmark score for camera in Android in 2023.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'According to DXOmark ratings, the Huawei P60 Pro is the phone with the top DXOmark score for camera in Android in 2023.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"which phone has top DXOmark score for camera in android in 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3083da05-03b1-441f-908d-519f4fb8bfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: First, I need to make sure it's the correct tournament and year.\n",
      "Action: Google Search\n",
      "Action Input: When did the first season of ICC Men's T20 World Cup happen?\n",
      "Observation:\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mThe first season of Twenty20 in England was a relative success. The first Twenty20 match held at Lord's, on 15 July 2004 between Middlesex and Surrey, attracted ... The first official Twenty20 matches were played on 13 June 2003 between the English counties in the T20 Blast. The first season of Twenty20 in England was a ... The inaugural match of the T20 World Cup was held in 2007, hosted by South Africa. The rest, as we know, is history. No, the ODI World Cup has been held in Australia in 1992 and 2015, but this is the first time they are hosting the T20 World Cup. It was ... Missing: Observation. Everything you need to know for Sunday's ICC Men's T20 World Cup final between Pakistan and England at the MCG. The first cricket match played at the MCG took place in September 1854 while Victoria and New South Wales met in the first inter-colonial match ... Missing: Observation. The winner of the International Cricket Council's Men's T20 World Cup 2022 in Australia will earn $1.6million in prize money from a total ... The International Cricket Council (ICC) has an-nounced the prize money for the upcoming men's T20 World Cup, scheduled to start October 16. When contacted by the Observer, the ICC insisted the delay in issuing the World Cup dates was not due to the India versus Pakistan issue and ...\u001b[0m\n",
      "intermediate step:\n",
      "\u001b[32;1m\u001b[1;3m Okay, so the first season of the ICC Men's T20 World Cup happened in 2007.\n",
      "Action: Google Search\n",
      "Action Input: Who was the captain of the winning team in the first season of ICC Men's T20 World Cup?\n",
      "Observation:\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mThe inaugural 2007 World Twenty20, was staged in South Africa, and won by India, who defeated Pakistan in the final at the Wanderers Stadium in Johannesburg. Winning teams, captains, and coachesEdit ; 2007 · South Africa · India ; 2009 · England · Pakistan ; 2010 · West Indies · England ; 2012 · Sri Lanka · West Indies ... Aaron Finch's side begin their Super 12 campaign with a repeat of last year's final. Missing: Observation. Shai Hope and Rovman Powell have been named captains of the West Indies white-ball teams, Cricket West Indies (CWI) has announced. Nicholas Pooran leads the West Indies in his first World Cup as captain, with Rovman Powell as vice-captain. Left-hand opening batter Evin Lewis ... Everything you need to know for Sunday's ICC Men's T20 World Cup final ... first two matches of the Super 12 stage, but Babar Azam's side ... Kane Williamson (New Zealand captain): “Everybody has different tags and rankings that go up and down throughout the year, and I suppose they ... Missing: Observation. The India captain said he entered his first ICC tournament with very little knowledge about how big the shortest format of the game would become ... Missing: Observation. The victory added to the 50-over title England won in 2019, building on the legacy of former Captain Eoin Morgan, who retired this year after ...\u001b[0m\n",
      "intermediate step:\n",
      "intermediate step more than 1:\n",
      "Thought:  Okay, so the first season of the ICC Men's T20 World Cup happened in 2007.\n",
      "Action: Google Search\n",
      "Action Input: Who was the captain of the winning team in the first season of ICC Men's T20 World Cup?\n",
      "Observation:\n",
      "Observation\n",
      "\u001b[32;1m\u001b[1;3m Great! So the captain of the winning team was Mahendra Singh Dhoni.\n",
      "Final Answer: Mahendra Singh Dhoni was the captain of the winning team in the first season of ICC Men's T20 World Cup.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Mahendra Singh Dhoni was the captain of the winning team in the first season of ICC Men's T20 World Cup.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"who was captain of team that won the first season of ICC Men's T20 World Cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bdb31e4a-7dd9-4034-8854-5afbf9f465d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Sam overhears Rick saying something negative about their living situation on the phone. Naomi suggests talking to Rick to address the issue, but Sam is hesitant due to potential conflict.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"\"\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions/tasks.\n",
    "USER: Summarize the conversation between 2 people given inside tripple backticks ```\n",
    "\n",
    "```Sam: hey overheard rick say something \n",
    "Sam: i don't know what to do :-/ \n",
    "Naomi: what did he say?? \n",
    "Sam: he was talking on the phone with someone \n",
    "Sam: i don't know who \n",
    "Sam: and he was telling them that he wasn't very happy here \n",
    "Naomi: damn!!! \n",
    "Sam: he was saying he doesn't like being my roommate \n",
    "Naomi: wow, how do you feel about it? \n",
    "Sam: i thought i was a good rommate \n",
    "Sam: and that we have a nice place \n",
    "Naomi: that's true man!!! \n",
    "Naomi: i used to love living with you before i moved in with me boyfriend \n",
    "Naomi: i don't know why he's saying that \n",
    "Sam: what should i do??? \n",
    "Naomi: honestly if it's bothering you that much you should talk to him\n",
    "Naomi: see what's going on \n",
    "Sam: i don't want to get in any kind of confrontation though \n",
    "Sam: maybe i'll just let it go \n",
    "Sam: and see how it goes in the future \n",
    "Naomi: it's your choice sam \n",
    "Naomi: if i were you i would just talk to him and clear the air.```\n",
    "ASSISTANT:\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
